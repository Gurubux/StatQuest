https://towardsdatascience.com/logistic-regression-detailed-overview-46c4da4303bc
https://developers.google.com/machine-learning/crash-course/logistic-regression/video-lecture
https://developers.google.com/machine-learning/crash-course/logistic-regression/calculating-a-probability

"https://christophm.github.io/interpretable-ml-book/logistic.html"

Regression models predict a continuous variable, such as rainfall amount or sunlight intensity. They can also predict probabilities, such as the probability that an image contains a cat. A probability-predicting regression model can be used as part of a classifier by imposing a decision rule - for example, if the probability is 50% or more, decide it's a cat.

Logistic regression predicts probabilities, and is therefore a regression algorithm. However, it is commonly described as a classification method in the machine learning literature, because it can be (and is often) used to make classifiers. There are also "true" classification algorithms, such as SVM, which only predict an outcome and do not provide a probability. We won't discuss this kind of algorithm here.
https://stats.stackexchange.com/questions/22381/why-not-approach-classification-through-regression

A solution for classification is logistic regression. Instead of fitting a straight line or hyperplane, the logistic regression model uses the logistic function to squeeze the output of a linear equation between 0 and 1. 
The logistic function is defined as:
									1
	logistic(η)				= ---------------
							  	1 + exp(−η)

							  		1
							= ---------------
							  	 1 + e⁻ⁿ


The step from linear regression to logistic regression is kind of straightforward. In the linear regression model, we have modelled the relationship between outcome and features with a linear equation:
					ŷ⁽ᶦ⁾=β₀ + β₁x₁⁽ᶦ⁾+…+βₚxₚ⁽ᶦ⁾
₀₁ₚ
For classification, we prefer probabilities between 0 and 1, so we wrap the right side of the equation into the logistic function. This forces the output to assume only values between 0 and 1.
				 							1
		P(y⁽ᶦ⁾=1) =			---------------------------------
							1 + exp(−(β₀ + β₁x₁⁽ᶦ⁾+…+βₚxₚ⁽ᶦ⁾))

