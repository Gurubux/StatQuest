-----------------------------------------------------------------------
CONFIDENCE INTERVALS
-----------------------------------------------------------------------
"https://www.datasciencecentral.com/profiles/blogs/confidence-intervals-in-one-picture"
-----------------------------------------------------------------------
"http://www.stats.gla.ac.uk/steps/glossary/confidence_intervals.html#conflim"
-----------------------------------------------------------------------

"https://github.com/Gurubux/StatQuest/blob/master/ConfidenceInterval/InferentialAnalysis_PointEstimates_ConfidenceIntervals.ipynb"
___________________________________________________________________________________________________________________
________________________CONFIDENCE INTERVAL - z-critical value - point estimate MEAN_________________________________
"If you KNOW THE STANDARD DEVIATION OF THE POPULATION, the margin of error is equal to:"
MARGIN OF ERROR    =	
   _______________
  /	 	    σ		   /
 /	z ∗ -----   /
/________√n____/		 
							where,
									σ (sigma) is the population standard deviation, ddof = 0, 
									n is sample size, and 
									z is a number known as the z-critical value, stats.norm.ppf(q = 0.975)

CONFIDENCE INTERVAL  = [ SAMPLE_MEAN  +  MARGIN OF ERROR , SAMPLE_MEAN -  MARGIN OF ERROR ]


The z-critical value is the number of standard deviations you`d have to go from the mean of the normal distribution to capture the proportion 
of the data associated with the desired confidence level. For instance, we know that roughly 95% of the data in a normal distribution lies
within 2 standard deviations of the mean, so we could use 2 as the z-critical value for a 95% confidence interval 
(although it is more exact to get z-critical values with stats.norm.ppf().).

print("MARGIN OF ERROR", stats.norm.ppf(q=0.025) ) # Find the quantile for the 2.5% cutoff # -1.95996398454 # ~ -2
print("MARGIN OF ERROR", stats.norm.ppf(q=0.975) ) # Find the quantile for the 97.5% cutoff # 1.95996398454 # ~  2


Let`s calculate a 95% confidence for our mean point estimate:
np.random.seed(10)

sample_size = 1000 # n
sample = np.random.choice(a= population_ages, size = sample_size)
sample_mean = sample.mean() # 42.523

z_critical = stats.norm.ppf(q = 0.975)  # Get the z-critical value* # z # 1.95996398454                     
pop_stdev = population_ages.std()  # Get the population standard deviation # σ
margin_of_error = z_critical * (pop_stdev/math.sqrt(sample_size)) #
confidence_interval = (sample_mean - margin_of_error,
                       sample_mean + margin_of_error)  
print(confidence_interval) #(41.703064068826833, 43.342935931173173)


# Let's create several confidence intervals and plot them to get a better sense of what it means to "capture" the true mean:
np.random.seed(12)
sample_size = 1000
intervals = []
sample_means = []

for sample in range(25):
    sample = np.random.choice(a= population_ages, size = sample_size)
    sample_mean = sample.mean()
    sample_means.append(sample_mean)
    z_critical = stats.norm.ppf(q = 0.975)  # Get the z-critical value*         
    pop_stdev = population_ages.std()  # Get the population standard deviation
    stats.norm.ppf(q = 0.025)
    margin_of_error = z_critical * (pop_stdev/math.sqrt(sample_size))
    confidence_interval = (sample_mean - margin_of_error,
                           sample_mean + margin_of_error)  
    intervals.append(confidence_interval)
>>>intervals
[(42.43806406882683, 44.07793593117317),
 (42.35506406882683, 43.99493593117317),
 (42.69006406882683, 44.32993593117317),
 (42.12106406882683, 43.76093593117317),
 ..., ...
 (42.09006406882683, 43.729935931173166),
 (43.40106406882683, 45.040935931173166),
 (41.96106406882683, 43.60093593117317),
 (42.43006406882683, 44.06993593117317)] 



# Plotting multiple Confidence interval based in comparision the true population mean = 43.0023
plt.figure(figsize=(15,9))

#Similar to confidence interval but Vertical line instead of Shade
"""plt.errorbar(x=np.arange(0.1, 50, 1), 
             y=sample_means, 
             yerr=[(top-bot)/2 for top,bot in intervals],
             fmt='o')"""
#Sample Means Line and points for 50 samples
plt.plot(np.arange(0.1, 50, 1),np.array([bot+(top-bot)/2 for top,bot in intervals]))
plt.scatter(np.arange(0.1, 50, 1),np.array([bot+(top-bot)/2 for top,bot in intervals]))

#Population Mean Line # 43.0023
plt.hlines(xmin=0, xmax=50,
           y=43.0023, 
           linewidth=2.0,
           color="red")
#Confidence Interval plot for confidence 95 or quantile 0.975
plt.fill_between(np.arange(0.1, 50, 1), [bot for top,bot in intervals],
                     [top for top,bot in intervals], alpha=0.1,
                     color="r")
___________________________________________________________________________________________________________________
________________________CONFIDENCE INTERVAL - t-critical value - point estimate MEAN_______________________________

"If you DON'T KNOW THE STANDARD DEVIATION OF THE POPULATION, the margin of error is equal to:"
MARGIN OF ERROR    = 
   __________________
  /	 	     σ		    /
 /	t ∗   -----    /
/__________√n_____/		 
							where,
									σ (sigma) is the Sample standard deviation, ddof = 1, 
									n is sample size, and 
									z is a number known as the t-critical value, stats.t.ppf(q = 0.975, df=n-1)

CONFIDENCE INTERVAL  = [ SAMPLE_MEAN  +  MARGIN OF ERROR , SAMPLE_MEAN -  MARGIN OF ERROR ]
	You have to use the standard deviation of your sample as a stand in when creating confidence intervals. 
Since the sample standard deviation may not match the population parameter the interval will have more error 
when you don`t know the population standard deviation. To account for this error, we use what's known as  

'T-CRITICAL VALUE' instead of the Z-CRITICAL value. 
The t-critical value is drawn from what`s known as a " t-distribution " --a distribution that closely resembles the normal distribution 
but that gets wider and wider as the sample size falls. 

The t-distribution is available in scipy.stats with the nickname "t" so we can get t-critical values with stats.t.ppf() instead of stats.norm.ppf().
------------------------------------
------------------------------------
Let`s take a new, SMALLER SAMPLE and then create a confidence interval without the population standard deviation, using the t-distribution:

np.random.seed(10)
sample_size = 25
sample = np.random.choice(a= population_ages, size = sample_size)
sample_mean = sample.mean()

t_critical = stats.t.ppf(q = 0.975, df=24)  # Get the t-critical value* 
#*Note: when using the t-distribution, you have to supply the degrees of freedom (df) UNLIKE stats.norm.ppf(q = 0.975)

print("t-critical value:")                  # Check the t-critical value
print(t_critical)                        

sample_stdev = sample.std(ddof=1)    # Get the sample standard deviation UNLIKE population_ages.std() where ddof=0
# In standard statistical practice, 
# 	ddof=1 provides an unbiased estimator of the variance of a hypothetical infinite population. 
# 	ddof=0 provides a maximum likelihood estimate of the variance for normally distributed variables.
# For sample the Std is TSS/√(n-1) instead of TSS/n And since in the Scipy formulae 
# 	the divisor used in calculations is N - ddof, where N represents the number of elements, and ddof is default 0 so passing 1 is mandatory
sigma = sample_stdev/math.sqrt(sample_size)  # Standard deviation estimate
margin_of_error = t_critical * sigma

confidence_interval = (sample_mean - margin_of_error,
                       sample_mean + margin_of_error)  

print("Confidence interval:")
print(confidence_interval)
>>>
t-critical value:
2.06389856163 # larger than z-critical value = 1.95996398454 
Confidence interval:
(37.757112737010608, 48.002887262989397)  
# The end result is a much wider confidence interval (an interval with a larger margin of error.)
# instead of (41.703064068826833, 43.342935931173173)
"Notice that the t-critical value is larger than the z-critical value we used for 95% confidence interval.
"This allows the confidence interval to CAST A LARGER NET TO MAKE UP FOR THE VARIABILITY caused by using the 
"sample standard deviation in place of the population standard deviation."

------------------------------------
------------------------------------
"If you have a large sample( > 25 ), the t-critical value will approach the z-critical value so there is 
"little difference between using the normal distribution vs. the t-distribution:"

# Check the difference between critical values with a sample size of 25 and 1000 for  t-critical and z-critical respectively
print(stats.t.ppf(q=0.975, df= 24) - stats.norm.ppf(0.975)  )
0.1039345770879665
# Check the difference between critical values with a sample size of 1000             
print(stats.t.ppf(q=0.975, df= 999) - stats.norm.ppf(0.975)  )
0.0023774765933946007

------------------------------------
------------------------------------
calculating a confidence interval using the Python function stats.t.interval():

stats.t.interval(alpha = 0.95,              # Confidence level
                 df= 24,                    # Degrees of freedom
                 loc = sample_mean,         # Sample mean
                 scale = sigma)             # Standard deviation estimate
(37.757112737010608, 48.002887262989397)  

_________________________________________________________________________________________________________________________
________________________CONFIDENCE INTERVAL - z-critical value - point estimate PROPORTION_______________________________
MARGIN OF ERROR    =     	
  	___________________
	 /	 		  p(1−p)    /
  /	z ∗	√   -----    /
 /___________n______/		 
							where,
									p the point estimate of the population proportion ,
									n is sample size, and 
									z is the z-critical value, stats.t.ppf(q = 0.975, df=24)

CONFIDENCE INTERVAL  = [ p  +  MARGIN OF ERROR , p -  MARGIN OF ERROR ]

z_critical = stats.norm.ppf(0.975)      # Record z-critical value
p = 0.192                               # Point estimate of proportion
n = 1000                                # Sample size
margin_of_error = z_critical * math.sqrt((p*(1-p))/n)
confidence_interval = (p - margin_of_error,  # Calculate the the interval
                       p + margin_of_error) 

(0.16758794241348748, 0.21641205758651252)

Calculate a confidence interval for a population proportion using the Python function tats.norm.interval()
stats.norm.interval(alpha = 0.95,    # Confidence level             
                   loc =  0.192,     # Point estimate of proportion
                   scale = math.sqrt((p*(1-p))/n))  # Scaling factor
(0.16758794241348748, 0.21641205758651252)

---------------------------------------------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------------------------------------------
https://github.com/Gurubux/StatQuest/blob/master/ConfidenceInterval/AnalysisOfVariance_ANOVA.ipynb
https://github.com/Gurubux/StatQuest/blob/master/ConfidenceInterval/CHI_SQUARED_TESTS.ipynb
https://github.com/Gurubux/StatQuest/blob/master/ConfidenceInterval/ConfidenceInterval.ipynb
https://github.com/Gurubux/StatQuest/blob/master/ConfidenceInterval/HypothesisTestingAndTheT_Test_ConfidenceInterval.ipynb



----------------------------------------------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------------------------------------------
8.9 #Draw Confidence level for Normal Curve, Z-Score -  CDF PDF PPF
draw_z_score(x, x<z0, 0, 1, 'z<-0.75')
sample_means = normal_curve_confidence_shade(population_ages,minnesota_ages,100)
#https://github.com/Gurubux/ML-Analysis-Steps/blob/master/InferentialStatistics/HypothesisTestingAndTheT-Test/HypothesisTestingAndTheT-Test.txt 
#https://github.com/Gurubux/ML-Analysis-Steps/blob/master/InferentialStatistics/HypothesisTestingAndTheT-Test/HypothesisTestingAndTheT_Test_ConfidenceInterval.ipynb

def normal_curve_confidence_shade(population_data,sample_data,sample_size):
  import numpy as np
  from sklearn.preprocessing import normalize
  np.random.seed(10)
  
  sample_means = []         # Make empty list to hold point estimates
  for x in range(200):         # Generate 200 samples
    sample = np.random.choice(a= sample_data, size=sample_size)
    sample_means.append( sample.mean() )
  
  fig=plt.figure(figsize=(15,9))
  
  plt.vlines(ymin=0, ymax=0.5,
           x=population_data.mean(), 
           linewidth=1.0,
           color="black",label=str('Population Mean %.2f'%population_data.mean()))
  
  plt.vlines(ymin=0, ymax=0.5,
           x=np.mean(sample_means), 
           linewidth=1.0,
           color="red",label=str('Sample Means Mean %.2f'%np.mean(sample_means)))
  
  plt.style.use('ggplot')
  mean=np.mean(sample_means)
  std=np.std(sample_means)
  
  x=np.arange(mean-6*std, mean+6*std,0.01)
  iq=stats.norm(mean,std)
  #plotting the normal curve
  plt.plot(x,stats.norm.pdf(x,mean,std),'black')
  intervals = stats.t.interval(alpha = 0.975,  # Confidence level
                 df = sample_size-1,                     # Degrees of freedom
                 loc = mean,                  # Sample mean
                 scale= sigma)
  px=np.arange(intervals[0],intervals[1],0.01)
  #plotting the normal curve
  plt.fill_between(px,iq.pdf(px),color='#1f77b4',label=str('97.5% Confidence {d[0]:.3f} to {d[1]:.3f}'.format(d=intervals)))
  
  intervals = stats.t.interval(alpha = 0.95,  # Confidence level
                 df = sample_size-1,                     # Degrees of freedom
                 loc = mean,                  # Sample mean
                 scale= sigma)
  px=np.arange(intervals[0],intervals[1],0.01)
  #plotting the normal curve
  plt.fill_between(px,stats.norm.pdf(px),color='#0a5386',label=str('95% Confidence {d[0]:.3f} to {d[1]:.3f}'.format(d=intervals)))
  
  intervals = stats.t.interval(alpha = 0.68,  # Confidence level
                 df = sample_size-1,                     # Degrees of freedom
                 loc = mean,                  # Sample mean
                 scale= sigma)
  px=np.arange(intervals[0],intervals[1],0.01)
  #Filling the 68% Confidence - 1 Z-critical
  plt.fill_between(px,iq.pdf(px),color='#173f5f',label=str('68% Confidence {d[0]:.3f} to {d[1]:.3f}'.format(d=intervals)))
  plt.legend()
  return sample_means
sample_means = normal_curve_confidence_shade(population_ages,minnesota_ages,100)  

def draw_z_score(x, cond, mu, sigma, title):
    y = stats.norm.pdf(x, mu, sigma)
    z = x[cond]
    plt.plot(x, y)
    #print(x,y,z)
    plt.fill_between(z, 0, stats.norm.pdf(z, mu, sigma))
    plt.title(title)
    plt.show()

x=np.arange(np.mean(sample_means)-6*np.std(sample_means), np.mean(sample_means)+6*np.std(sample_means),0.001)
intervals = stats.t.interval(alpha = 0.68,  # Confidence level
                 df = 100-1,                     # Degrees of freedom
                 loc = np.mean(sample_means),                  # Sample mean
                 scale= sigma)
z0,z1 = intervals
draw_z_score(x, (z0 < x) & (x < z1),np.mean(sample_means), np.std(sample_means), '-0.75<z<0.75')